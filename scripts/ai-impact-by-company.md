# AI Impact on Insurance Companies

*Key takeaways from the 3 most recent 10-K filings (FY2022-FY2024) for each of the 41 InsurIntel companies. Extracted from SEC EDGAR on 2026-02-07.*

---

## P&C (15 companies)

### CB — Chubb Limited
- FY2022 filing had zero AI mentions (only generic "data analytics" references); by FY2023-2024, CB added substantial AI language covering NAIC Model Bulletin compliance, EU AI Act, cyber deepfake risks, and competitive concerns -- a clear reactive ramp-up rather than proactive adoption.
- CB's CTO holds a degree in artificial intelligence and computer science, and the company has a dedicated Cyber Advisory Board of external experts, signaling serious institutional investment in AI/cyber governance at the leadership level.
- CB is leveraging "global data and artificial intelligence assets" specifically in Asia for digital partnership distribution and bancassurance, positioning AI as a growth enabler for its composite insurer strategy in emerging markets.
- AI-related risk disclosures focus heavily on cybersecurity: bad actors deploying AI for vulnerability exploitation, deepfakes, and long-term persistent attacks, with CB acknowledging that AI adoption "may intensify cybersecurity risks."
- CB cites the NAIC Model Bulletin (adopted by 19 state insurance departments as of FY2024) and the EU AI Act as key regulatory concerns, noting that compliance "may require changes in our operations, increase compliance costs and reduce benefits from our adoption of artificial intelligence technologies."

### PGR — Progressive Corporation
- Progressive explicitly states it has "developed, and used for many years, new technologies, including machine learning and other forms of artificial intelligence, predictive models, algorithms and automated processes" -- one of the strongest self-identified long-duration AI track records among P&C carriers.
- FY2022 filing focused on NAIC guiding principles and state-level regulatory scrutiny of algorithms/ML; by FY2023-2024, Progressive added an entirely new dedicated GenAI risk factor section, reflecting how quickly generative AI reshaped the disclosure landscape.
- GenAI risks are articulated with unusual specificity: flawed/biased datasets leading to "unintentionally and unfairly discriminatory outcomes," reputational risk from public debate over AI use, IP ownership uncertainties around GenAI inputs/outputs and copyright, and vendor GenAI compliance risk.
- Progressive highlights competitive risk from both directions: competitors or third parties may incorporate GenAI "more quickly, or more successfully, than us," while state regulators may "impose marketing restrictions or requirements related to the use of artificial intelligence and third-party data."
- The company is notably candid that AI regulatory risk could "impact our operations or ability to write business profitably in one or more jurisdictions," citing NAIC actions, state rulemaking, and the unsettled nature of AI-related IP law.

### TRV — Travelers Companies
- Travelers is one of the few P&C carriers to describe concrete AI investment in operations: "invested significant additional resources in many of its claims handling operations, including digital, analytics, artificial intelligence and automation capabilities," monitored for "consistent optimization among outcomes, cost and service."
- FY2024 filing added new language about AI creating "unforeseen exposures or coverage issues under the policies we write" and aggravating "claims fraud and cybercrime" -- positioning AI as a direct underwriting exposure risk, not just an operational tool.
- In FY2023, Travelers explicitly tied AI to its ongoing technology strategy, noting that "business processes become more digital and seek to incorporate artificial intelligence, and certain of our products, such as cyber insurance, are more technology-based."
- Competitive concern is framed around big data analysis: if competitors deploy AI/ML to "collect and analyze a wide variety of data points to make underwriting or other decisions" more effectively, or access data Travelers cannot, it could harm competitive positioning.
- Travelers identifies AI talent as a scarce resource, noting intense competition for "specialized knowledge in areas such as underwriting, data and analytics, technology, claims and artificial intelligence," taking place on a "broad geographic scale" due to remote work.

### ALL — Allstate Corporation
- Allstate is actively deploying LLMs in customer-facing operations: FY2024 filing states they are "using large language models to improve customer communications" and continuing to "build a digital enterprise by expanding utilization of machine-based learning and artificial intelligence" -- among the most specific GenAI use-case disclosures in the P&C sector.
- Notable evolution: FY2022 mentioned only "artificial intelligence and machine learning"; FY2023 added "large language models" as a named technology; FY2024 added "predictive analytics" and hedged that "the maturity and effectiveness of currently available generative artificial intelligence technology is uncertain."
- Allstate owns Arity, a dedicated telematics and mobility insights subsidiary that provides data to insurers, the transportation industry, and consumer apps -- a distinctive competitive moat in data-driven underwriting that complements AI/ML capabilities.
- Third-party AI risk is called out explicitly: vendors may "deploy new technologies, such as artificial intelligence, in a manner that has an adverse impact on our operations," and cloud/SaaS dependencies "can make it more difficult to identify and respond to cyberattacks."
- Allstate frames AI as presenting "ethical and reputational risks" and notes that "regulatory restrictions on the use of artificial intelligence may impose additional compliance or reporting obligations" that could affect profitability.

### AIG — American International Group
- AIG has the most prominent strategic AI positioning in its FY2024 filing, listing as a key strategic priority: "Responsibly scale the use of generative artificial intelligence (AI), focus on continued enhancement of data quality to inform decision making and further strengthen workflow capabilities across the company" -- explicitly naming GenAI as a scaling initiative.
- AIG created a dedicated regulatory section titled "Privacy, Data Protection, Cybersecurity and Artificial Intelligence Requirements" spanning multiple pages, covering DORA, the NAIC Model Bulletin (adopted December 2023), the EU AI Act (effective August 2026), and state-specific Colorado/New York regulations.
- Cybersecurity disclosures are particularly detailed: AIG warns about "advancing forms of artificial intelligence and quantum computing by nation state threat actors and criminal organizations" and that "deepfake schemes" require "significant attention to identification, assessment and analysis."
- AIG acknowledges increasing reliance on AI systems: "we rely heavily on information technology and systems (which is expected to increasingly include the use of artificial intelligence)" -- framing AI integration as a given, not a question.
- Regulatory risk language sharpened significantly from FY2022 (generic EU AI Act proposal mention) to FY2024 (specific citations of NAIC model bulletin, Colorado governance requirements, NYDFS Circular Letter 7, and the EU AI Act's August 2024 effective date).

### HIG — Hartford Financial Services
- Hartford demonstrates concrete AI deployment across its business lines: the ICON quoting tool enables "over 75% of Spectrum package business and workers compensation new business policies" to be quoted "without human intervention," one of the most specific automation metrics disclosed by any P&C carrier.
- FY2024 strategy explicitly describes "investing in end-to-end transformation, responsibly leveraging data, analytics, digital and artificial intelligence capabilities to drive better, faster decisions and enhance customer experiences" and "expanding its use of data analytics, artificial intelligence capabilities and third party data to make risk selection and pricing decisions."
- Hartford uniquely identifies AI as a risk to workers' compensation demand: "increased use of advanced analytics (e.g., artificial intelligence) and automation in the workplace could potentially affect the demand for workers' compensation insurance products over time" -- a sector-specific exposure given Hartford's large WC book.
- Clear evolution from FY2022 (mentioned AI only once, in a strategy bullet about "data and analytics and technology, including artificial intelligence") to FY2024 (8+ high-signal AI mentions spanning operations, competition, regulation, cybersecurity, and technology risk).
- Regulatory awareness includes NAIC Model Bulletin adoption at state level, noting "regulators have recently requested information from insurers on their use of algorithms, artificial intelligence and machine learning."

### ACGL — Arch Capital Group
- Arch Capital's FY2024 filing contains a standout dedicated "Artificial Intelligence" section in the business description -- not just risk factors -- stating they use AI for "catastrophe modeling and predictive analytics to help mitigate losses" and to "provide more information about past experiences and submissions, thus allowing our professionals to make more data driven underwriting decisions."
- GenAI governance is explicitly described: "The use of generative AI technologies is reviewed and monitored very closely with approval required for each new generative AI technology proposed for use in our operations" -- suggesting a formal gating process rather than ad hoc adoption.
- Massive shift from FY2022 (zero AI mentions) to FY2024 (20+ AI-related mentions across operational use, regulation, cyber risks, and competitive positioning), one of the largest year-over-year disclosure expansions in the P&C sector.
- ACGL provides unusually detailed regulatory coverage including the Trump executive order on AI (January 2025), California ADMT proposed rules that broadly define automated decision-making to include AI/ML/profiling, and the NAIC model bulletin.
- The company acknowledges vulnerability in GenAI adoption speed: "our pace of adoption of new technologies, such as generative AI, may not be adequate to meet the demands of our customers or impact negatively our ability to compete with our peers."

### WRB — W.R. Berkley Corporation
- FY2022 filing had zero AI-related mentions; FY2023-2024 added extensive regulatory and risk language, suggesting WRB was a late mover in AI disclosure -- though the regulatory detail is among the most thorough in the sector.
- WRB's FY2024 filing provides the most detailed state-level regulatory mapping of any P&C carrier, citing: NAIC Model Bulletin, NAIC's 2024 new task force on third-party data/predictive models, Colorado's ECDIS law and Division of Insurance governance framework (with December 2024 draft amendment for auto/health), and NYDFS Circular Letter 7.
- GenAI is acknowledged as presenting unknown risks: "because some AI technologies are relatively new, such as generative AI, many of the potential risks regarding their use are currently unknown," with concerns including misuse of personal data, model/training data flaws, and unauthorized AI use by employees.
- Operational AI use is described in general terms -- "Products or services offered that develop or adopt artificial intelligence technologies, including generative AI and machine learning, offer potential benefits (e.g., with respect to efficiency)" -- but lacks the specificity of peers like Hartford or Arch Capital.
- Third-party AI risk is a notable concern: WRB warns of exposure to "risks associated with artificial intelligence and machine learning technology if third-party service providers or any counterparts, whether known or unknown to us, use such technology."

### CINF — Cincinnati Financial
- Cincinnati Financial is one of the few carriers to describe a specific operational AI deployment: "We have implemented artificial intelligence technology that has reduced data entry time and improved the quality of our data analytics" -- a concrete efficiency gain, though modest in scope compared to peers.
- AI is explicitly tied to Cincinnati Financial's pricing strategy: "Limitations on our ability to use various types of artificial intelligence (AI) in the development of pricing precision could adversely affect underwriting results," showing direct linkage between AI and underwriting profitability.
- The life insurance division specifically calls out AI: "Artificial intelligence and improved computing power will continue to allow us to improve our efficiency in writing new business and servicing it," with underwriting evolving to use models evaluating "mortality risk without requiring invasive and time intensive traditional medical exams."
- Vendor AI governance is noteworthy: when evaluating vendors, CINF considers "the use of artificial intelligence, interactions with our systems, the data involved and its level of sensitivity" -- indicating a formalized third-party AI risk assessment process.
- FY2022 had zero AI mentions; FY2023 added AI pricing risk and ML regulatory scrutiny language; FY2024 expanded significantly with operational deployment and vendor governance details.

### MKL — Markel Group
- Markel's AI disclosures are almost entirely risk-focused with no description of specific operational AI use cases; the filings focus on risks from "increased usage of artificial intelligence by us and third parties" and the "evolving regulatory landscape" without detailing how Markel itself deploys AI.
- Third-party AI risk is a dominant theme: Markel warns that third parties performing technology/business process functions may use AI "without our knowledge or below our standards, which could result in monetary and reputational damages" -- repeated verbatim across FY2023 and FY2024.
- The company frames AI as both an underwriting risk and an opportunity cost, but provides no specifics on what "appropriate" AI leverage looks like.
- FY2022 had zero AI mentions (only data analytics and InsurTech references), placing Markel among the latest adopters of AI-specific disclosure language in the P&C sector.

### CNA — CNA Financial
- CNA's AI disclosures are minimal and lag peers significantly: FY2022 had zero AI mentions; FY2023 added a single brief reference; FY2024 expanded modestly but remains thin compared to sector leaders.
- The most substantive FY2024 AI statement describes competitive risk: "more insurers are utilizing or may begin utilizing 'big data' analytics or artificial intelligence to make underwriting or other decisions that impact product design and pricing."
- CNA identifies AI as a cybersecurity amplifier: "the increasing use of artificial intelligence, both within our systems to achieve operational efficiencies and within threat actors' attack strategies, may further expose our systems to the risk of cyber-attacks."
- Distribution channel disruption from AI is flagged: agents and brokers utilizing "greater levels of data and technology, including artificial intelligence, could adversely impact our business relationship with independent agents and brokers."
- No specific AI operational deployments, GenAI initiatives, or detailed regulatory awareness are disclosed -- a notable gap suggesting CNA may be a laggard in AI adoption.

### ERIE — Erie Indemnity
- Erie's FY2022 filing contained zero AI mentions; FY2023 added four AI references; FY2024 expanded to five, primarily framing AI as a competitive threat and cyber risk rather than an operational capability.
- The company acknowledges AI as a competitive threat: "Innovations, including the use of artificial intelligence and machine learning to support underwriting or other decisions, by competitors or other market participants may increase the level of competition in the industry."
- Cybersecurity risk from AI is called out: "Even with appropriate governance and controls, the use of artificial intelligence may increase our exposure to cyber threats."
- Erie identifies talent needs in AI as a specific concern: "talented employees in actuarial, finance, human resources, law, risk management and information technology, including artificial intelligence and data analytics, are also essential."
- No specific AI operational deployments or GenAI initiatives are described; filings suggest Erie is in an early evaluation phase.

### AFG — American Financial Group
- AFG made a distinctive strategic bet on AI through its December 2021 acquisition of Verikai, Inc. for $120 million -- an ML/AI company with a "predictive risk tool to assess insurance risk" that continues operating as a stand-alone subsidiary serving insurance clients.
- Despite owning an AI company, AFG's 10-K AI disclosures are surprisingly thin: FY2024 added only generic "AFG may utilize artificial intelligence and machine learning in its business" language, with risk-focused caveats about mispricing and overpaying claims.
- The Verikai acquisition gives AFG a potentially unique competitive asset in AI-powered underwriting risk assessment, but the "may utilize" language suggests integration into AFG's own operations may still be incomplete.
- No GenAI-specific disclosures, NAIC Model Bulletin references, or EU AI Act language appears in any filing -- a notable omission given the regulatory landscape other carriers address extensively.

### ORI — Old Republic International
- ORI is among the most AI-sparse filers in the P&C sector: FY2022 and FY2023 had zero AI mentions; FY2024 added only two AI-related references, both risk-focused.
- The FY2024 AI language is almost entirely boilerplate: "emerging types of artificial intelligence (AI) could disrupt the Company's operations, result in financial losses, the loss of critical and confidential information, or expose the Company to additional liabilities."
- No operational AI deployments, specific use cases, strategic AI investments, or detailed regulatory awareness are disclosed -- ORI appears to be a clear laggard.

### AIZ — Assurant
- Assurant has the most differentiated AI use case in the P&C sector: in October 2024, it opened an "Innovation and Device Care Center" supporting mobile device lifecycle solutions and "the development of new and innovative ways to leverage automation, robotics and artificial intelligence" -- tying AI directly to its core connected device business.
- Assurant leverages "digital solutions supported by artificial intelligence" to "introduce innovative products and services and continuously adapt those offerings to the changing needs of consumers," framing AI as a product innovation enabler.
- Regulatory awareness evolved significantly: FY2023 cited NAIC guiding principles and Biden's October 2023 Executive Order; FY2024 upgraded to reference the NAIC Model Bulletin (adopted by ~20 states), Colorado/New York/California state-specific AI regulations, and the EU AI Act.
- FY2022 had zero AI-specific mentions; the company has progressively built out AI disclosure each year, moving from monitoring posture to active deployment by FY2024.

---

## Life (9 companies)

### MET — MetLife
- FY2022 10-K had zero AI mentions; FY2023 introduced substantial language around NAIC AI Bulletin adoption, Colorado's binding regulation requiring life insurers to adopt AI governance frameworks, and NYDFS proposed circular letter on AI in underwriting/pricing -- a clear FY2022-to-FY2023 awakening.
- FY2024 filing explicitly calls out GenAI as presenting "significant opportunities but also complex challenges," noting risks of harm from development or deployment of AI technologies and the need to maintain controls for an "evolving and increasingly complex AI regulatory landscape."
- Regulatory exposure spans multiple jurisdictions: NAIC Model Bulletin on AI Systems, EU AI Act (effective 2024), Colorado's first binding regulation on AI governance for life insurers, and NYDFS Circular Letter No. 7 on AI in underwriting and pricing.
- No specific operational AI use cases are disclosed -- language is entirely risk-factor and regulatory-awareness oriented, suggesting MetLife treats AI primarily as a compliance challenge rather than a competitive differentiator in its public filings.
- Colorado's regulation (requiring governance and risk management frameworks for AI/ML using external consumer data) is particularly relevant to MetLife's life insurance underwriting.

### PRU — Prudential Financial
- Clear FY2022-to-FY2024 escalation: FY2022 mentions were limited to NAIC researching big data/AI and accelerated life underwriting; by FY2023 and FY2024, Prudential added an extensive dedicated GenAI risk factor section.
- Identifies specific AI use cases as "customer service personalization and process automation" and states it expects to use GenAI to "help deliver products and services and support critical functions" -- but these remain forward-looking aspirations rather than deployed capabilities.
- Highlights a competitive risk dimension: "Our competitors may also adopt AI or Generative AI more quickly or more effectively than we do, which could cause competitive harm," and explicitly acknowledges that hardware/network capacity constraints may limit AI adoption.
- FY2024 filing adds NYDFS Circular Letter No. 7 (July 2024) and Colorado AI Law (SB 24-205, effective Feb 2026) to the regulatory landscape, showing the regulatory burden expanding rapidly year over year.
- Key risk framing: GenAI "may be misused by us or by such third parties" and "many of the potential risks are currently unknowable" -- Prudential is notably cautious about third-party AI risk propagation through vendors.

### AFL — Aflac
- Minimal AI substance across all three filing years -- FY2022 had zero AI-specific mentions. Aflac appears to be a notable laggard in AI disclosure among Life sector peers.
- FY2023 and FY2024 added near-identical language acknowledging NIST AI risk guidelines and the NAIC Model Bulletin, plus a brief mention that the company is investing in "digital capabilities and product innovation including the development and use of artificial intelligence (AI)."
- The only operational signal is a risk warning that "the Company's development of new technology, including the use of AI by the Company and third-party vendors, could lead to an increased risk of a business interruption or a cybersecurity breach."
- Aflac invests in private equity in insurtech/healthtech companies, suggesting ecosystem awareness, but no disclosure of specific AI-powered underwriting, claims, or customer service capabilities.
- No GenAI-specific language appears in any filing year, making Aflac one of the few Life sector companies without explicit GenAI risk disclosure by FY2024.

### CRBG — Corebridge Financial
- Among the most detailed AI disclosures in the Life sector. Explicitly states that "AI plays a role in certain aspects of our business" and that "underwriting processes with respect to our Life Insurance segment use algorithms and predictive models" -- one of the few Life companies to confirm current operational AI use.
- FY2024 filing significantly expanded from FY2023: added EU AI Act, Colorado's algorithmic accountability law, and NYDFS Circular Letter 7 as specific regulatory references, and notes the company is "exploring wider uses of advanced technologies in our operating environments."
- Identifies AI as both a cybersecurity attack vector ("techniques used in these threats may change rapidly, including the use of emerging technologies, such as broader forms of artificial intelligence") and a defensive tool.
- Regulatory concern is extensive: calls out increased scrutiny of "machine learning, predictive models and artificial intelligence" from Colorado, New York, and federal regulators, and warns that "any limitations imposed as a result of regulatory actions could have a material impact on our business."
- FY2022 (first filing as a public company) already had substantial AI regulatory language, tracking the EU AI Act proposal from its inception -- suggesting sophisticated regulatory monitoring from day one.

### PFG — Principal Financial Group
- Extremely sparse AI disclosure -- the weakest in the Life sector. FY2022 and FY2023 had zero AI-specific mentions; the only recurring term was "data analytics" in a generic talent recruitment context.
- FY2024 added a single meaningful AI mention referencing "EU AI Act, Colorado AI Act, and other AI-related legislation," noting these "will continue to increase and require attention and investments." Entirely compliance-oriented with no operational detail.
- No mentions of GenAI, machine learning, predictive models, or any specific AI use cases across any filing year.
- The absence is particularly notable given PFG's asset management and retirement services business, where AI-driven portfolio optimization and customer engagement would be expected.

### EQH — Equitable Holdings
- Significant FY2022-to-FY2024 evolution: FY2022 had only a single mention of predictive models in life underwriting; by FY2023 and FY2024, EQH added extensive GenAI risk factor language.
- FY2024 is notably detailed on regulatory developments: references the NAIC Big Data and Artificial Intelligence (H) Working Group's new workstream evaluating "AI-use outcomes," the Third-Party Data and Models Task Force, and signals that a comprehensive "AI regulatory framework" may come in 2025.
- Confirms operational use of predictive models in underwriting ("through the use of predictive models") and expects to use GenAI for "customer service personalization and process automation."
- Colorado's binding regulation requiring life insurers to adopt AI governance frameworks for external consumer data is directly applicable to EQH's life insurance segment.
- Competitive framing warns that competitors "may adopt AI or generative AI more quickly or more effectively," and acknowledges that "many of the potential risks of generative AI are currently unknowable."

### UNM — Unum Group
- Clear FY2022-to-FY2024 escalation: FY2022 had zero AI mentions; FY2024 introduced a dedicated AI risk factor with operationally direct language: "We currently use, and expect to continue using, artificial intelligence (AI), including generative AI, in support of our products, services, and critical business functions."
- FY2024 disclosure explicitly addresses both internally developed and third-party AI technology, acknowledging that "increased reliance on AI, coupled with the fact that the laws and regulations governing the use of AI are still in a relatively early stage of development, may increase regulatory or operational risks."
- Regulatory awareness is comprehensive: cites numerous states adopting the NAIC Model Bulletin, the EU AI Act coming into effect, and the NAIC's Third-Party Data and Models (H) Task Force.
- Uniquely notes the risk of "potential regulations governing individual rights with respect to the usage of AI" -- a forward-looking concern about AI-related individual rights that most peers have not yet flagged.
- Frames AI compliance costs as a direct business impact: "Changes in privacy, cybersecurity, and artificial intelligence laws and regulations may result in cost increases as a result of system implementations, administrative processes, effects of potential noncompliance, and limitations or constraints of our business models."

### GL — Globe Life
- The weakest AI disclosure in the entire Life sector. FY2022 and FY2023 had zero AI mentions of any kind. FY2024 added a single sentence: the company's IT modernization "includes the responsible and secure use of emerging technologies like artificial intelligence."
- No mentions of GenAI, machine learning, predictive models, NAIC Model Bulletin, EU AI Act, Colorado regulation, or any other specific AI regulatory framework across any filing year.
- The sole AI reference is embedded in a cybersecurity/IT infrastructure risk paragraph, suggesting Globe Life views AI purely as an IT modernization item rather than a strategic initiative.
- This near-total silence on AI is a meaningful signal: Globe Life's direct-to-consumer life and supplemental health model (heavily agent-driven) may not yet be deploying AI at a reportable scale.

### LNC — Lincoln National
- Consistent AI disclosure across all three filing years, with language focused on regulatory risk from big data/AI use in "underwriting, sales and marketing and in claims processing" -- one of the few Life companies to specifically name these operational domains.
- FY2023 filing notably references the October 2023 White House Executive Order on AI in addition to the NAIC guiding principles and model bulletin, showing Lincoln tracks federal-level AI policy alongside state insurance regulation.
- FY2023 introduced the "Spark Initiative" context (launched 2021) focused on "driving efficiencies throughout all aspects of our business, from leveraging automation to simplifying and improving process efficiency" -- an operational transformation backdrop into which AI tools would naturally integrate.
- Regulatory framing is compliance-first: "We cannot predict how existing and emerging guidance, rules and regulations governing the use of AI will be interpreted or applied."
- No GenAI-specific language appears in any filing year, and no specific AI tools, vendors, or deployment details are disclosed.

---

## Health (7 companies)

### UNH — UnitedHealth Group
- FY2022 filing had zero AI/ML mentions -- only a generic "advanced analytics" reference to Optum Insight, making UNH a notable late-mover in 10-K AI disclosure despite being the largest health insurer by revenue.
- Starting in FY2023, UNH added substantial AI/ML risk language: data integrity failures in "systems powered by or incorporating AI/ML" could impair medical cost estimates, pricing, fraud detection, and customer retention -- framing AI primarily as an operational dependency risk.
- UNH explicitly anticipates generative AI will play "an increasingly important role" in customer-facing technology products and information systems, but provides no specifics on deployed use cases -- language remains forward-looking and aspirational.
- Cybersecurity risk disclosures flag AI/ML (including generative AI) as a tool used by threat actors to increase attack sophistication, making existing defenses potentially inadequate.
- Regulatory exposure spans U.S. federal/state and international (EU, UK, Chile, India) jurisdictions with emerging AI/ML and automation laws; UNH acknowledges compliance costs may "constrain or require us to alter our business model or operations."

### CI — Cigna Group
- Cigna shows the most detailed and mature AI governance of any Health sector filer: it established an "AI Center of Enablement" (AI COE) in FY2023 specifically for generative AI, staffed cross-functionally with technology, privacy, legal, compliance, security, and marketing teams to evaluate and approve Gen AI use cases against its "Responsible AI Principles."
- Operationally, Cigna uses predictive analytics and ML/deep learning to create "actionable intelligence" that informs clinical decision-making, behavioral health interventions (identifying at-risk members proactively), and pharmacy benefit management -- consistent across FY2022-FY2024.
- Cigna explicitly states "We do not view AI as a replacement for expert decisions made by physicians or employees" (FY2024), positioning AI as augmentation rather than automation of clinical judgment -- a notable framing amid industry scrutiny of AI-driven utilization management denials.
- Regulatory risk disclosures expanded significantly from FY2022 (mentioning FTC enforcement focus on AI fairness) to FY2024 (adding EU AI Act and Digital Operational Resilience Act compliance obligations).
- In FY2022, AI was mentioned only as an "emerging trend"; by FY2023-2024, Cigna had a dedicated AI risk factor section -- the sharpest escalation in AI-specific risk disclosure among Health filers.

### ELV — Elevance Health
- Elevance established a formal "Responsible Artificial Intelligence (RAI) Program" led by its Chief Digital and Information Officer, embedded within the enterprise risk management framework -- one of the few Health filers to give AI its own named governance program at the board level.
- FY2023 filing was the first to explicitly mention large language models, warning that "AI and business processes supported by large language models may not operate as expected or may lead to unintentional bias, discrimination and/or data exposure."
- AI risk disclosures explicitly flag "negative consumer perceptions as to the use of automation and AI" as a reputational threat, alongside accuracy, bias, discrimination, IP infringement, and data privacy -- a broader risk taxonomy than most peers.
- Despite the governance structure, Elevance's operational AI disclosures remain thin: filings describe "sophisticated data analytics" for member engagement via the Sydney Health platform, but lack specifics on AI/ML model deployments.

### HUM — Humana
- Humana is the weakest AI discloser in the Health sector: FY2022 and FY2023 10-Ks contain zero mentions of AI, ML, or generative AI -- only boilerplate "sophisticated data analytics" references repeated identically across filing years.
- The FY2024 filing marks an abrupt shift, adding AI/ML and generative AI language for the first time -- but it is entirely risk-focused: systems incorporating "artificial intelligence and machine learning (including generative AI)" require significant resources to maintain.
- Humana discloses no AI governance structure, no specific AI use cases, and no strategic AI positioning in any filing year -- a significant gap for a company with 17M+ members and heavy Medicare Advantage exposure.
- The three-year pattern (zero AI mentions through FY2023, then sudden risk-only language in FY2024) suggests Humana adopted industry-standard AI risk boilerplate rather than reflecting an organic AI strategy.

### CNC — Centene Corporation
- Centene's most distinctive AI asset is Apixio (acquired subsidiary), which uses AI for retrospective chart reviews and risk score submission to CMS -- the most specific, production-deployed AI use case disclosed by any Health filer, though it appears only in the FY2022 filing.
- FY2024 filing contains the most detailed AI regulatory risk language of any Health filer, specifically referencing HHS's 2023 finalized "transparency requirements for artificial intelligence and other predictive algorithms used in certified health information technology."
- Centene explicitly warns that "changes to laws and regulations regarding how we may use artificial intelligence could make it harder for us to conduct our business using AI; require us to retrain our AI; or prevent or limit our use of AI."
- LLM risk is called out directly: "business processes supported by large language models that are used by us, our healthcare providers, our brokers, or our third-party vendors may not operate as expected."
- Board-level oversight expanded from FY2023 (Audit and Compliance Committee with AI-specific oversight) to FY2024's additional risk factor language, but no formal AI governance program is described.

### MOH — Molina Healthcare
- Molina is making "appreciable investments in certain AI administrative tools and initiatives" focused on operational efficiencies and cost savings -- language consistent in FY2023 and FY2024, suggesting a multi-year program but with no specifics on which administrative functions are being targeted.
- The company explicitly warns that AI investments may produce "operational improvements, efficiencies, and cost savings that are less than anticipated, or that result in unforeseen consequences" -- an unusually candid downside-case framing.
- FY2024 added AI-as-cyber-threat language not present in FY2023: techniques to "circumvent, gain access to, or sabotage security systems can be highly sophisticated, may use advanced technologies (such as artificial intelligence)."
- Regulatory risk language specifically references the January 2025 Trump administration rescission of the Biden executive order on AI safety, noting resulting "uncertainty regarding the applicable regulations."
- FY2022 filing contains zero AI mentions. The jump to explicit AI investment language in FY2023 represents a material strategy shift.

### CVS — CVS Health
- CVS has the most operationally specific AI deployment in the Health sector: its "Canopy" clinical platform integrates payor claims data, pharmacy data, and medical records, then uses AI/ML to "create and refine a clinical rules engine (predictive models and prescriptive algorithms) that informs care delivery and addresses hospital admissions and readmissions, medical costs and patient retention."
- Pharmacy benefit management uses "assisted artificial intelligence to deliver insights to the business and bring automation to otherwise manual tasks" at retail, mail, and specialty pharmacies -- a production AI deployment consistent across all three filing years.
- State-level AI regulation is called out as a compliance burden: "differing approaches to state privacy, cybersecurity and/or artificial intelligence regulation and varying enforcement philosophies may significantly restrict the Company's ability to standardize its products and services across state lines."
- Despite strong operational AI language, CVS has no disclosed AI governance structure, responsible AI program, or GenAI-specific initiative -- a notable gap compared to CI's AI Center of Enablement or ELV's Responsible AI Program.

---

## Reinsurance (4 companies)

### BRK.B — Berkshire Hathaway
- Zero AI-related mentions across all three filing years (FY2022, FY2023, FY2024). Berkshire's 10-K contains no references to artificial intelligence, machine learning, generative AI, data analytics, insurtech, or automation.
- The complete absence likely reflects Berkshire's conglomerate structure and Warren Buffett's historically sparse 10-K risk factor disclosures rather than a literal absence of AI activity across its subsidiaries (GEICO, Gen Re, etc.).

### RNR — RenaissanceRe Holdings
- RNR views AI primarily as a competitive threat to the hard market cycle: its FY2024 10-K warns that "increased access to capital, new technologies, including artificial intelligence, and other factors may reduce the duration or eliminate or significantly lessen the impact of any current or future hard reinsurance underwriting market."
- AI is flagged as a cybersecurity amplifier across all three years. The FY2024 filing added language that "artificial intelligence technologies are quickly evolving and being adopted, which may increase or intensify potential cybersecurity risks."
- RNR makes strategic investments in InsurTech opportunities for "target risk-adjusted returns" and to "advance business objectives and capabilities," positioning itself as an investor in, not just user of, technology-driven reinsurance.
- No mentions of specific AI tools, GenAI initiatives, or proprietary AI platforms. RNR's AI posture is defensive (risk-oriented) rather than operational, with no disclosed use of AI in its core catastrophe modeling or underwriting functions.

### EG — Everest Group
- EG's AI mentions are almost entirely regulatory and cyber-risk boilerplate. FY2022 filing had zero AI-related mentions; FY2024 added references to the NAIC Insurance Data Security Model Law and NYDFS cybersecurity regulation.
- The one substantive operational mention is predictive analytics for climate risk: "underwriting, actuarial and catastrophe modelling teams work together in researching and analyzing external raw climate/meteorological data in conjunction with our internal proprietary claims and loss information data to develop predictive analytics models to refine pricing tolerances and product development."
- No mentions of GenAI, machine learning tools, or AI-driven operational initiatives. EG's disclosed AI posture is limited to climate-related predictive analytics and compliance-oriented regulatory awareness.

### RGA — Reinsurance Group of America
- RGA's AI mentions center on regulatory scrutiny of big data and ML in insurance, specifically citing the NAIC's adopted "principles to guide the use of artificial intelligence intended to apply to insurance licensees."
- The company warns it may face "restrictions and limitations on the way we implement the use of personal data, big data or machine learning" and that failure to comply "could have a material impact on new and existing business."
- RGA's CIO has "deep knowledge in organizational change, digital transformation, core platform and data analytics modernization," signaling internal modernization efforts, but no specific AI tools or initiatives are disclosed.
- FY2022 filing had zero AI mentions. The identical language in FY2023 and FY2024 filings (copy-paste across years) suggests standard risk factor disclosures rather than evidence of evolving AI strategy.

---

## Brokers (6 companies)

### MMC — Marsh & McLennan
- MMC is the clear AI leader among brokers, with a named internal GenAI tool: "LenAI," described as an "internal generative AI tool" that "was designed to meet our standards for data security and to address and mitigate the risks associated with this new technology." This is the only company in the dataset with a named, proprietary GenAI platform.
- Oliver Wyman (MMC subsidiary) acquired Veritas Total Solutions in FY2024, a firm with "expertise in risk, systems, analytics and artificial intelligence," and runs a Digital practice that "accelerates and embeds digital transformation" for clients. Guy Carpenter has an explicit InsurTech specialty practice.
- MMC identifies GenAI as both an investment priority and a cybersecurity risk vector, noting that "the advance of AI and large language models has given rise to additional vulnerabilities" and that "increasing use of generative AI models in our internal systems may create new attack methods for adversaries."
- The company acknowledges risks from third-party AI tools leaking confidential information "into publicly available training sets."
- Clear evolution from FY2022 (no GenAI references, AI mentioned only as a competitive threat from InsurTech) to FY2024 (extensive GenAI discussion, LenAI deployment, IP/confidentiality risks from third-party AI).

### AON — Aon plc
- AON explicitly states it is investing "in artificial intelligence, particularly in generative artificial intelligence tools, and have developed governance and oversight measures regarding its use" (FY2024) -- naming GenAI as a specific investment priority with formal governance structures.
- AON identifies operational risk from AI outputs: "Certain use cases of artificial intelligence in our business processes could pose operational, legal or reputational risks where there may be incorrect outputs or bias in those systems or processes, or where there is inadequate human oversight."
- The company warns that "innovations in software, cloud computing, data and analytics, generative artificial intelligence, or other technologies that alter how our services are delivered could significantly undermine our investment in the business if we are slow to innovate."
- AON flags deepfakes specifically as a GenAI-enabled cybersecurity threat. This language appeared first in FY2023 and continued in FY2024.
- Sharp evolution: FY2022 had only 3 generic AI mentions (competitive threat, cybersecurity); FY2024 jumped to 8 mentions with specific GenAI investment disclosures, governance frameworks, and bias/output-quality risk factors.

### AJG — Arthur J. Gallagher
- AJG names two proprietary data platforms: "Gallagher Drive" for client-facing data analysis and benchmarking insights, and "SmartMarket" for providing insurance carriers with "individualized preference setting" -- data analytics tools positioned as competitive differentiators, though not explicitly AI-branded.
- Risk factors consistently frame AI as both opportunity and threat: "failure to apply technology, data analytics and artificial intelligence (which we refer to as AI) effectively" is listed as a top risk factor across all three filing years.
- The company faces intense competition for AI talent: FY2024 notes "competition for talent is intense in many areas of our business, particularly in our claims management business, our IT organization and in rapidly developing fields such as artificial intelligence and data engineering."
- AJG acknowledges competitive risk from AI-driven services including "generative AI, machine learning, robotics, blockchain, or new approaches to data mining." The filings are notably consistent across FY2022-FY2024 with near-identical language, suggesting a stable but not rapidly evolving AI posture.
- No named GenAI tools or specific GenAI initiatives. AJG's approach appears centered on data analytics and technology platforms rather than frontier AI adoption.

### WTW — Willis Towers Watson
- WTW shows the clearest year-over-year AI disclosure escalation among brokers. FY2022 had only 2 mentions; FY2023 added AI and ML as "Data Tools" for efficiency; FY2024 exploded to 14 mentions with extensive GenAI cybersecurity risk language and board-level AI oversight.
- WTW established a dedicated board Risk Committee that explicitly oversees "cybersecurity, technology, information security, privacy, and artificial intelligence risk" -- the only company in the dataset disclosing board-level AI risk governance.
- WTW identifies GenAI as a competitive imperative: "incorporating AI into certain product offerings is becoming more important in our operations, particularly as our competitors, including new entrants focused on using technology and innovation, such as generative AI, digital platforms, data analytics, robotics and blockchain, seek to simplify and improve the client experience."
- The company discloses extensive GenAI cybersecurity risk: threat actors using GenAI to "automate breaches or persistent attacks, evade detection, or generate sophisticated phishing emails."
- WTW's ongoing "right-shoring strategy and automation of our operations" indicates operational automation investments predating the GenAI wave.

### BRO — Brown & Brown
- BRO has minimal AI disclosure: only 2 mentions in FY2024, zero in FY2023, zero in FY2022. This is the sparsest AI footprint among all brokers.
- The FY2024 filing does confirm operational AI use: "we use artificial intelligence (AI) and robotic processing automation (RPA) in our business, including with respect to services provided to our customers."
- BRO has "internal policies governing the use of AI and RPA by our employees designed to protect us from breaches of data privacy, errors and omissions liability and regulatory enforcement risk," indicating a governance framework exists despite light disclosure.
- No mention of GenAI, machine learning, data analytics platforms, or specific technology initiatives. BRO's competitive positioning relies on its decentralized, acquisition-driven model rather than technology differentiation.

### RYAN — Ryan Specialty Holdings
- RYAN frames AI adoption cautiously: "We may incorporate artificial intelligence (AI) solutions into our platform, offerings, services, and features" and competitors "may incorporate AI into their products and services more quickly or more successfully than us." The "may incorporate" language suggests AI is aspirational, not yet deployed.
- FY2023 filing specifically mentions the NAIC's "proposed model bulletin for states to adopt that would guide the insurance industry towards assuring that the use of such technologies does not cause unfair discrimination," and the CCPA's California Privacy Protection Agency proposing new AI regulations.
- RYAN identifies AI-related E&O risk: "challenges with properly adopting and managing its use could result in reputational harm, competitive harm, legal liability."
- FY2022 had only a single generic insurtech mention. FY2023 jumped to 8 mentions with detailed AI regulatory and competitive risk factors. FY2024 maintained 6 mentions -- growing awareness but no specific operational deployment.
